{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLyqpuhlOrbvvzXUSLsHRC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imtufail/Machine-Learning-Contents/blob/main/Understanding-Data/Basic_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# distribution in a dataset\n",
        " helps you understand how values are spread across different columns. This is a key step before modeling or preprocessing.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Useful information you can extract from distributions:\n",
        "\n",
        "#### 1. **Value concentration (skewness)**\n",
        "\n",
        "* Do most values fall in a small range?\n",
        "* Is the data **left-skewed**, **right-skewed**, or **symmetric**?\n",
        "\n",
        "Helps in choosing normalization or transformation methods.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Outliers**\n",
        "\n",
        "* Do some values fall far outside the typical range?\n",
        "\n",
        "Outliers can distort models and may need to be removed or capped.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Class imbalance (for categorical variables)**\n",
        "\n",
        "* Are some classes much more frequent than others?\n",
        "\n",
        "Useful in classification problems. Example: 95% class A, 5% class B ‚Üí model may always predict A.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Spread (variance, standard deviation)**\n",
        "\n",
        "* Is the column tightly packed or widely spread?\n",
        "\n",
        "Important for algorithms sensitive to scale (e.g., k-NN, SVM).\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. **Data types and encoding needs**\n",
        "\n",
        "* Are categorical values evenly distributed or dominated by a few?\n",
        "\n",
        "This helps decide whether to use one-hot, label, or frequency encoding.\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. **Missing values or zero dominance**\n",
        "\n",
        "* Does a feature have too many zeroes or NaNs?\n",
        "\n",
        "High zero-rate columns may need special treatment or removal.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Why distributions are applied per column:\n",
        "\n",
        "Each column carries different meaning and scale:\n",
        "\n",
        "* Age: right-skewed (more young people)\n",
        "* Income: highly skewed (few rich, many average)\n",
        "* Gender: balanced or imbalanced\n",
        "\n",
        "Understanding **per-column distribution** tells you:\n",
        "\n",
        "* What transformations to apply (log, binning, etc.)\n",
        "* Whether scaling is needed\n",
        "* Which features are useful, redundant, or harmful\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Tools to view distributions:\n",
        "\n",
        "* `df['column'].hist()` or `sns.histplot(df['column'])`\n",
        "* `sns.boxplot(df['column'])`\n",
        "* `value_counts()` for categorical\n",
        "* `describe()` for numeric summaries\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "acM3GADp1cT_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_lr_-kBiRgw"
      },
      "outputs": [],
      "source": []
    }
  ]
}